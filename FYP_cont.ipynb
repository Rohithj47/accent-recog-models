{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN = np.loadtxt('X_train_NN.txt')\n",
    "Y_train = np.loadtxt('Y_train.txt')\n",
    "X_test_NN = np.loadtxt('X_test_NN.txt')\n",
    "Y_test  = np.loadtxt('Y_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lab = []\n",
    "for i in range(59):\n",
    "    if Y_test[i][0] == 1.0:\n",
    "        y_lab.append(1)\n",
    "    if Y_test[i][1] == 1.0:\n",
    "        y_lab.append(2)\n",
    "    if Y_test[i][2] == 1.0:\n",
    "        y_lab.append(3)\n",
    "    if Y_test[i][3] == 1.0:\n",
    "        y_lab.append(4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               83328     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 87,588\n",
      "Trainable params: 87,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_NN  = tf.keras.models.Sequential()\n",
    "\n",
    "model_NN.add(tf.keras.layers.Dense(units= 128, activation= 'relu', input_shape = (650,)))\n",
    "model_NN.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model_NN.add(tf.keras.layers.Dense(units= 4, activation= 'softmax'))\n",
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 746us/sample - loss: 35.2118 - acc: 0.2667\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 110us/sample - loss: 13.4905 - acc: 0.3571\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 118us/sample - loss: 9.5107 - acc: 0.4333\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 106us/sample - loss: 5.7752 - acc: 0.5143\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 113us/sample - loss: 3.0905 - acc: 0.6619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x132aa15c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN.fit(X_train_NN, Y_train, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 1ms/sample - loss: 8.4566 - acc: 0.3220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.456582974579375, 0.3220339]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN.evaluate(X_test_NN, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 932us/sample\n",
      "[[0 5 2 5 5]\n",
      " [0 0 6 4 0]\n",
      " [0 6 4 3 7]\n",
      " [0 2 4 1 5]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_predNN = model_NN.predict_classes(X_test_NN, verbose= 1)\n",
    "print(metrics.confusion_matrix(y_predNN, y_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_NN.reshape(210, 13,50)\n",
    "X_test = X_test_NN.reshape(X_test_NN.shape[0], 13,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 13, 32)            4832      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 13, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 832)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               106624    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 118,180\n",
      "Trainable params: 118,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN  = tf.keras.models.Sequential()\n",
    "\n",
    "model_CNN.add( tf.keras.layers.Conv1D(filters= 32, kernel_size= 3, padding = 'same', activation= 'relu', input_shape =[13,50]))\n",
    "model_CNN.add( tf.keras.layers.MaxPool1D(pool_size= 2, strides = 1, padding = 'same'))\n",
    "model_CNN.add( tf.keras.layers.Conv1D(filters= 64, kernel_size= 3, padding = 'same', activation= 'relu'))\n",
    "model_CNN.add( tf.keras.layers.MaxPool1D(pool_size= 2, strides = 1, padding = 'same'))\n",
    "model_CNN.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model_CNN.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_CNN.add(tf.keras.layers.Dense(units = 128, activation= 'relu'))\n",
    "model_CNN.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model_CNN.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 1ms/sample - loss: 52.1234 - acc: 0.2952\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 208us/sample - loss: 26.8625 - acc: 0.2571\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 214us/sample - loss: 12.4593 - acc: 0.2667\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 207us/sample - loss: 6.3513 - acc: 0.3143\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 211us/sample - loss: 4.7052 - acc: 0.3905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1330104a8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN.fit(X_train, Y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/sample - loss: 3.0117 - acc: 0.2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0116913641913463, 0.27118644]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 1ms/sample\n",
      "[[ 0  2  1  1  0]\n",
      " [ 0  9 13 12 16]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  1  2  0  1]\n",
      " [ 0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "y_predCNN = model_CNN.predict_classes(X_test, verbose= 1)\n",
    "print(metrics.confusion_matrix(y_predCNN, y_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 121,204\n",
      "Trainable params: 121,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN = tf.keras.models.Sequential()\n",
    "model_RNN.add(tf.keras.layers.LSTM(150, input_shape= (13,50)))\n",
    "model_RNN.add(tf.keras.layers.Dropout(0.2))\n",
    "model_RNN.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "model_RNN.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 1s 3ms/sample - loss: 1.5856 - acc: 0.2095\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 884us/sample - loss: 1.1577 - acc: 0.5238\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 952us/sample - loss: 0.8966 - acc: 0.7524\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 870us/sample - loss: 0.7382 - acc: 0.8571\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 929us/sample - loss: 0.5941 - acc: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1349835c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN.fit(X_train, Y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/sample - loss: 1.3115 - acc: 0.3220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3115336106995406, 0.3220339]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/sample\n",
      "[[0 3 2 1 3]\n",
      " [0 3 6 6 3]\n",
      " [0 4 1 3 4]\n",
      " [0 3 7 3 7]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_predRNN = model_RNN.predict_classes(X_test, verbose= 1)\n",
    "print(metrics.confusion_matrix(y_predRNN, y_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_NN_Norm = preprocessing.normalize(X_train_NN)\n",
    "X_test_NN_Norm = preprocessing.normalize(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 128)               83328     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 87,588\n",
      "Trainable params: 87,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_NN_Norm_MFCC  = tf.keras.models.Sequential()\n",
    "\n",
    "model_NN_Norm_MFCC.add(tf.keras.layers.Dense(units= 128, activation= 'relu', input_shape = (650,)))\n",
    "model_NN_Norm_MFCC.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model_NN_Norm_MFCC.add(tf.keras.layers.Dense(units= 4, activation= 'softmax'))\n",
    "model_NN_Norm_MFCC.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN_Norm_MFCC.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 775us/sample - loss: 1.3737 - acc: 0.2952\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 111us/sample - loss: 1.3434 - acc: 0.3429\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 116us/sample - loss: 1.3314 - acc: 0.3429\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 112us/sample - loss: 1.3237 - acc: 0.3429\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 115us/sample - loss: 1.3142 - acc: 0.3429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1333a1400>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN_Norm_MFCC.fit(X_train_NN_Norm, Y_train, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/sample - loss: 1.3824 - acc: 0.2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3824218309531777, 0.27118644]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN_Norm_MFCC.evaluate(X_test_NN_Norm, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Norm = np.empty([210,13,50])\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_Norm[i] = preprocessing.normalize(X_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_Norm = np.empty([59,13,50])\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_Norm[i] = preprocessing.normalize(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 13, 8)             1208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 13, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 420       \n",
      "=================================================================\n",
      "Total params: 1,628\n",
      "Trainable params: 1,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN_Norm  = tf.keras.models.Sequential()\n",
    "\n",
    "model_CNN_Norm.add( tf.keras.layers.Conv1D(filters= 8, kernel_size= 3, padding = 'same', activation= 'relu', input_shape =[13,50]))\n",
    "model_CNN_Norm.add( tf.keras.layers.MaxPool1D(pool_size= 2, strides = 1, padding = 'same'))\n",
    "model_CNN_Norm.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model_CNN_Norm.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_CNN_Norm.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "\n",
    "model_CNN_Norm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN_Norm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 928us/sample - loss: 1.4021 - acc: 0.2524\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 137us/sample - loss: 1.3802 - acc: 0.3143\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 121us/sample - loss: 1.3554 - acc: 0.3000\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 132us/sample - loss: 1.3522 - acc: 0.3238\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 132us/sample - loss: 1.3307 - acc: 0.3667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x136d3b9b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN_Norm.fit(X_train_Norm, Y_train, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/sample - loss: 1.3947 - acc: 0.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3947178428455935, 0.33898306]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN_Norm.evaluate(X_test_Norm, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 121,204\n",
      "Trainable params: 121,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN_Norm = tf.keras.models.Sequential()\n",
    "model_RNN_Norm.add(tf.keras.layers.LSTM(150, input_shape= (13,50)))\n",
    "model_RNN_Norm.add(tf.keras.layers.Dropout(0.2))\n",
    "model_RNN_Norm.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "model_RNN_Norm.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN_Norm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 1s 4ms/sample - loss: 1.3774 - acc: 0.2476\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 936us/sample - loss: 1.3357 - acc: 0.3762\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 997us/sample - loss: 1.3159 - acc: 0.3714\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 1ms/sample - loss: 1.2965 - acc: 0.3714\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 1ms/sample - loss: 1.2750 - acc: 0.4143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x138249160>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN_Norm.fit(X_train_Norm, Y_train, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/sample - loss: 1.3862 - acc: 0.3220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.386245426485094, 0.3220339]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN_Norm.evaluate(X_test_Norm, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conversion by taking mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_train = np.empty([210,13]) \n",
    "lc = X_train.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(13):\n",
    "        X_mean_train[i][j] = sum(X_train[i][j])/len(X_train[i][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_test = np.empty([59,13]) \n",
    "lc = X_test.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(13):\n",
    "        X_mean_test[i][j] = sum(X_test[i][j])/len(X_test[i][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ne_train = []\n",
    "for i in range(210):\n",
    "    if Y_train[i][0] == 1.0:\n",
    "        y_ne_train.append(1)\n",
    "    if Y_train[i][1] == 1.0:\n",
    "        y_ne_train.append(2)\n",
    "    if Y_train[i][2] == 1.0:\n",
    "        y_ne_train.append(3)\n",
    "    if Y_train[i][3] == 1.0:\n",
    "        y_ne_train.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_notenc_train = np.array(y_ne_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ne_test = []\n",
    "for i in range(59):\n",
    "    if Y_test[i][0] == 1.0:\n",
    "        y_ne_test.append(1)\n",
    "    if Y_test[i][1] == 1.0:\n",
    "        y_ne_test.append(2)\n",
    "    if Y_test[i][2] == 1.0:\n",
    "        y_ne_test.append(3)\n",
    "    if Y_test[i][3] == 1.0:\n",
    "        y_ne_test.append(4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_notenc_test = np.array(y_ne_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 4, 4, 1, 2, 4, 3, 2, 1, 2, 1, 1, 4, 4, 2, 4, 1, 3, 1, 3,\n",
       "       4, 3, 1, 3, 3, 4, 3, 4, 2, 1, 4, 4, 3, 3, 1, 3, 3, 2, 4, 2, 1, 1,\n",
       "       4, 4, 2, 2, 2, 2, 2, 3, 2, 1, 4, 3, 4, 2, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_notenc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3389830508474576\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 1000, random_state= 42)\n",
    "rf.fit(X_mean_train, y_notenc_train)\n",
    "rf_pred = rf.predict(X_mean_test)\n",
    "print(accuracy_score(y_notenc_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2711864406779661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithjanardhan/mlpath/yourenv/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_mfcc = SVC()\n",
    "svc_mfcc.fit(X_mean_train, y_notenc_train)\n",
    "svc_mfcc_pred = svc_mfcc.predict(X_mean_test)\n",
    "print(accuracy_score(y_notenc_test, svc_mfcc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_norm_train = np.empty([210,13]) \n",
    "lc = X_train_Norm.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(13):\n",
    "        X_mean_norm_train[i][j] = sum(X_train_Norm[i][j])/len(X_train_Norm[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_norm_test = np.empty([59,13]) \n",
    "lc = X_test_Norm.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(13):\n",
    "        X_mean_norm_test[i][j] = sum(X_test_Norm[i][j])/len(X_test_Norm[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23728813559322035\n"
     ]
    }
   ],
   "source": [
    "rf_norm_mfcc = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_norm_mfcc.fit(X_mean_norm_train, y_notenc_train)\n",
    "rf_pred_norm = rf_norm_mfcc.predict(X_mean_norm_test)\n",
    "print(accuracy_score(y_notenc_test, rf_pred_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2711864406779661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithjanardhan/mlpath/yourenv/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sv_norm_mfcc = SVC()\n",
    "sv_norm_mfcc.fit(X_mean_norm_train, y_notenc_train)\n",
    "sv_norm_mfcc_pred = sv_norm_mfcc.predict(X_mean_norm_test)\n",
    "print(accuracy_score(y_notenc_test, sv_norm_mfcc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ms_NN = np.loadtxt('X_train_ms_NN.txt')\n",
    "X_test_ms_NN = np.loadtxt('X_test_ms_NN.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 823,588\n",
      "Trainable params: 823,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 2ms/sample - loss: 4.7130 - acc: 0.2667\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 283us/sample - loss: 1.2885 - acc: 0.5048\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 309us/sample - loss: 0.8964 - acc: 0.6190\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 576us/sample - loss: 0.6693 - acc: 0.7333\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 350us/sample - loss: 0.5175 - acc: 0.8190\n",
      "59/59 [==============================] - 0s 4ms/sample - loss: 3.0863 - acc: 0.3051\n",
      "\n",
      " Accuracy is  0.30508474\n"
     ]
    }
   ],
   "source": [
    "model_ms_NN  = tf.keras.models.Sequential()\n",
    "\n",
    "model_ms_NN.add(tf.keras.layers.Dense(units= 128, activation= 'relu', input_shape = (6400,)))\n",
    "model_ms_NN.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model_ms_NN.add(tf.keras.layers.Dense(units= 4, activation= 'softmax'))\n",
    "model_ms_NN.summary()\n",
    "model_ms_NN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_ms_NN.fit(X_train_ms_NN, Y_train, epochs = 5)\n",
    "_,acc = model_ms_NN.evaluate(X_test_ms_NN, Y_test)\n",
    "print('\\n NN Accuracy is ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ms = X_train_ms_NN.reshape(210,128,50)\n",
    "X_test_ms = X_test_ms_NN.reshape(59,128,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 128, 8)            1208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 5,308\n",
      "Trainable params: 5,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 1ms/sample - loss: 6.1792 - acc: 0.2333\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 228us/sample - loss: 4.9374 - acc: 0.2810\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 216us/sample - loss: 3.5539 - acc: 0.3286\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 223us/sample - loss: 3.0623 - acc: 0.3238\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 258us/sample - loss: 2.4955 - acc: 0.3857\n",
      "59/59 [==============================] - 0s 3ms/sample - loss: 4.0337 - acc: 0.2881\n",
      "\n",
      " CNN Accuracy is  0.2881356\n"
     ]
    }
   ],
   "source": [
    "model_ms_CNN  = tf.keras.models.Sequential()\n",
    "\n",
    "model_ms_CNN.add( tf.keras.layers.Conv1D(filters= 8, kernel_size= 3, padding = 'same', activation= 'relu', input_shape =[128,50]))\n",
    "model_ms_CNN.add( tf.keras.layers.MaxPool1D(pool_size= 2, strides = 1, padding = 'same'))\n",
    "model_ms_CNN.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model_ms_CNN.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_ms_CNN.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "\n",
    "model_ms_CNN.summary()\n",
    "\n",
    "model_ms_CNN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_ms_CNN.fit(X_train_ms, Y_train, epochs = 5)\n",
    "_,acc = model_ms_CNN.evaluate(X_test_ms, Y_test)\n",
    "print('\\n CNN Accuracy is ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 121,204\n",
      "Trainable params: 121,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 2s 10ms/sample - loss: 1.3881 - acc: 0.3286\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 2s 7ms/sample - loss: 1.3616 - acc: 0.3762\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 2s 7ms/sample - loss: 1.3370 - acc: 0.3857\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 2s 7ms/sample - loss: 1.3022 - acc: 0.3667\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 1s 7ms/sample - loss: 1.2824 - acc: 0.3857\n",
      "59/59 [==============================] - 0s 6ms/sample - loss: 1.3801 - acc: 0.3220\n",
      "\n",
      " RNN Accuracy is  0.3220339\n"
     ]
    }
   ],
   "source": [
    "model_ms_RNN = tf.keras.models.Sequential()\n",
    "model_ms_RNN.add(tf.keras.layers.LSTM(150, input_shape= (128,50)))\n",
    "model_ms_RNN.add(tf.keras.layers.Dropout(0.2))\n",
    "model_ms_RNN.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "model_ms_RNN.summary()\n",
    "\n",
    "model_ms_RNN.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_ms_RNN.fit(X_train_ms, Y_train, epochs= 5)\n",
    "_,acc = model_ms_RNN.evaluate(X_test_ms, Y_test)\n",
    "print('\\n RNN Accuracy is ',acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ms_Norm_NN  = preprocessing.normalize(X_train_ms_NN)\n",
    "X_test_ms_Norm_NN = preprocessing.normalize(X_test_ms_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 823,588\n",
      "Trainable params: 823,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 2ms/sample - loss: 1.3860 - acc: 0.2476\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 256us/sample - loss: 1.3678 - acc: 0.3810\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 263us/sample - loss: 1.3375 - acc: 0.3667\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 265us/sample - loss: 1.2987 - acc: 0.3952\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 261us/sample - loss: 1.2547 - acc: 0.4857\n",
      "59/59 [==============================] - 0s 3ms/sample - loss: 1.4105 - acc: 0.2203\n",
      "\n",
      " NN Accuracy is  0.22033899\n"
     ]
    }
   ],
   "source": [
    "model_ms_NN_Norm  = tf.keras.models.Sequential()\n",
    "\n",
    "model_ms_NN_Norm.add(tf.keras.layers.Dense(units= 128, activation= 'relu', input_shape = (6400,)))\n",
    "model_ms_NN_Norm.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "model_ms_NN_Norm.add(tf.keras.layers.Dense(units= 4, activation= 'softmax'))\n",
    "model_ms_NN_Norm.summary()\n",
    "model_ms_NN_Norm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_ms_NN_Norm.fit(X_train_ms_Norm_NN, Y_train, epochs = 5)\n",
    "_,acc = model_ms_NN_Norm.evaluate(X_test_ms_Norm_NN, Y_test)\n",
    "print('\\n NN Accuracy is ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ms_Norm = X_train_ms_Norm_NN.reshape(210,128,50)\n",
    "X_test_ms_Norm = X_test_ms_Norm_NN.reshape(59,128,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 128, 8)            1208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 5,308\n",
      "Trainable params: 5,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 0s 2ms/sample - loss: 1.3833 - acc: 0.3048\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 0s 287us/sample - loss: 1.3714 - acc: 0.3476\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 0s 268us/sample - loss: 1.3572 - acc: 0.3429\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 0s 262us/sample - loss: 1.3457 - acc: 0.3429\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 0s 279us/sample - loss: 1.3416 - acc: 0.3429\n",
      "59/59 [==============================] - 0s 4ms/sample - loss: 1.4154 - acc: 0.2712\n",
      "\n",
      " CNN Accuracy is  0.27118644\n"
     ]
    }
   ],
   "source": [
    "model_ms_CNN_Norm  = tf.keras.models.Sequential()\n",
    "\n",
    "model_ms_CNN_Norm.add( tf.keras.layers.Conv1D(filters= 8, kernel_size= 3, padding = 'same', activation= 'relu', input_shape =[128,50]))\n",
    "model_ms_CNN_Norm.add( tf.keras.layers.MaxPool1D(pool_size= 2, strides = 1, padding = 'same'))\n",
    "model_ms_CNN_Norm.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model_ms_CNN_Norm.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model_ms_CNN_Norm.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "\n",
    "model_ms_CNN_Norm.summary()\n",
    "\n",
    "model_ms_CNN_Norm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_ms_CNN_Norm.fit(X_train_ms_Norm, Y_train, epochs = 5)\n",
    "_,acc = model_ms_CNN_Norm.evaluate(X_test_ms_Norm, Y_test)\n",
    "print('\\n CNN Accuracy is ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 121,204\n",
      "Trainable params: 121,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 3s 13ms/sample - loss: 1.3818 - acc: 0.3286\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 3s 13ms/sample - loss: 1.3586 - acc: 0.3429\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 2s 8ms/sample - loss: 1.3832 - acc: 0.3429\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 2s 7ms/sample - loss: 1.3576 - acc: 0.3429\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 2s 7ms/sample - loss: 1.3613 - acc: 0.3429\n",
      "59/59 [==============================] - 0s 6ms/sample - loss: 1.3827 - acc: 0.2712\n",
      "\n",
      " RNN Accuracy is  0.27118644\n"
     ]
    }
   ],
   "source": [
    "model_ms_RNN_Norm = tf.keras.models.Sequential()\n",
    "model_ms_RNN_Norm.add(tf.keras.layers.LSTM(150, input_shape= (128,50)))\n",
    "model_ms_RNN_Norm.add(tf.keras.layers.Dropout(0.2))\n",
    "model_ms_RNN_Norm.add(tf.keras.layers.Dense(units = 4, activation= 'softmax'))\n",
    "model_ms_RNN_Norm.summary()\n",
    "\n",
    "model_ms_RNN_Norm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_ms_RNN_Norm.fit(X_train_ms_Norm, Y_train, epochs= 5)\n",
    "_,acc = model_ms_RNN_Norm.evaluate(X_test_ms_Norm, Y_test)\n",
    "print('\\n RNN Accuracy is ',acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_ms_train = np.empty([210,128]) \n",
    "lc = X_train_ms.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(128):\n",
    "        X_mean_ms_train[i][j] = sum(X_train_ms[i][j])/len(X_train_ms[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_ms_test = np.empty([59,128]) \n",
    "lc = X_test_ms.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(128):\n",
    "        X_mean_ms_test[i][j] = sum(X_test_ms[i][j])/len(X_test_ms[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3220338983050847\n"
     ]
    }
   ],
   "source": [
    "rf_ms = RandomForestClassifier(n_estimators= 1000, random_state= 42)\n",
    "rf_ms.fit(X_mean_ms_train, y_notenc_train)\n",
    "rf_ms_pred = rf_ms.predict(X_mean_ms_test)\n",
    "print(accuracy_score(y_notenc_test, rf_ms_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3389830508474576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithjanardhan/mlpath/yourenv/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_ms = SVC()\n",
    "svc_ms.fit(X_mean_ms_train, y_notenc_train)\n",
    "svc_ms_pred = svc_ms.predict(X_mean_ms_test)\n",
    "print(accuracy_score(y_notenc_test, svc_ms_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_ms_train_Norm = np.empty([210,128]) \n",
    "lc = X_train_ms_Norm.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(128):\n",
    "        X_mean_ms_train_Norm[i][j] = sum(X_train_ms_Norm[i][j])/len(X_train_ms_Norm[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_ms_test_Norm = np.empty([59,128]) \n",
    "lc = X_test_ms_Norm.shape[0]\n",
    "for i in range(lc):\n",
    "    for j in range(128):\n",
    "        X_mean_ms_test_Norm[i][j] = sum(X_test_ms_Norm[i][j])/len(X_test_ms_Norm[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2711864406779661\n"
     ]
    }
   ],
   "source": [
    "rf_norm_ms = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_norm_ms.fit(X_mean_ms_train_Norm, y_notenc_train)\n",
    "rf_pred_norm_ms = rf_norm_ms.predict(X_mean_ms_test_Norm)\n",
    "print(accuracy_score(y_notenc_test, rf_pred_norm_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2711864406779661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohithjanardhan/mlpath/yourenv/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sv_norm_ms = SVC()\n",
    "sv_norm_ms.fit(X_mean_ms_train_Norm, y_notenc_train)\n",
    "sv_norm_ms_pred = sv_norm_ms.predict(X_mean_ms_test_Norm)\n",
    "print(accuracy_score(y_notenc_test, sv_norm_ms_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
